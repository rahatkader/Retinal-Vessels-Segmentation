{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Retinal_Vessels_Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahatkader/Retinal-Vessels-Segmentation/blob/main/Retinal_Vessels_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Retinal Vessels Segmentation**\n",
        "\n",
        "* Inspired from: https://github.com/CVxTz/medical_image_segmentation.git\n",
        "* Dataset available at: https://www.isi.uu.nl/Research/Databases/DRIVE/"
      ],
      "metadata": {
        "id": "8v-rDH6QBbK7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation\n",
        "Part of the script from aug_utils.py"
      ],
      "metadata": {
        "id": "wI3rsH1n_Hb7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import"
      ],
      "metadata": {
        "id": "dFWU-Xdk_kAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras_preprocessing import image\n",
        "from PIL import Image\n",
        "import cv2"
      ],
      "metadata": {
        "id": "X3M8Td6U_cYS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### random_flip"
      ],
      "metadata": {
        "id": "-HzCWutK_sZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_flip(img, mask, u=0.5):\n",
        "    if np.random.random() < u:    # np.random.random() Return random floats in the half-open interval [0.0, 1.0)\n",
        "        img = image.flip_axis(img, 1)\n",
        "        mask = image.flip_axis(mask, 1)\n",
        "    if np.random.random() < u:\n",
        "        img = image.flip_axis(img, 0)\n",
        "        mask = image.flip_axis(mask, 0)\n",
        "    return img, mask"
      ],
      "metadata": {
        "id": "yk1PgaS1_eTp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### random_rotate"
      ],
      "metadata": {
        "id": "on5vXQkL_w3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_rotate(img, mask, rotate_limit=(-20, 20), u=0.5):\n",
        "    if np.random.random() < u:\n",
        "        theta = np.random.uniform(rotate_limit[0], rotate_limit[1]) # np.random.uniform Draw samples from a uniform distribution\n",
        "        img = image.apply_affine_transform(img, theta=theta)\n",
        "        mask = image.apply_affine_transform(mask, theta=theta)\n",
        "    return img, mask"
      ],
      "metadata": {
        "id": "B4JDY3gx_176"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### shift"
      ],
      "metadata": {
        "id": "uObh8klD_7FC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shift(x, wshift, hshift, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest', cval=0.):\n",
        "    h, w = x.shape[row_axis], x.shape[col_axis]\n",
        "    tx = hshift * h\n",
        "    ty = wshift * w\n",
        "    x = image.apply_affine_transform(x, ty=ty, tx=tx)\n",
        "    return x"
      ],
      "metadata": {
        "id": "0dp16nPqACu6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### random_shift"
      ],
      "metadata": {
        "id": "VgRTGeoiAEEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_shift(img, mask, w_limit=(-0.1, 0.1), h_limit=(-0.1, 0.1), u=0.5):\n",
        "    if np.random.random() < u:\n",
        "        wshift = np.random.uniform(w_limit[0], w_limit[1])\n",
        "        hshift = np.random.uniform(h_limit[0], h_limit[1])\n",
        "        img = shift(img, wshift, hshift)\n",
        "        mask = shift(mask, wshift, hshift)\n",
        "    return img, mask"
      ],
      "metadata": {
        "id": "8qpxsIFFAG56"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### random_zoom"
      ],
      "metadata": {
        "id": "2Ai-UQFzAJiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_zoom(img, mask, zoom_range=(0.8, 1), u=0.5):\n",
        "    if np.random.random() < u:\n",
        "        zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\n",
        "        img = image.apply_affine_transform(img, zx=zx, zy=zy)\n",
        "        mask = image.apply_affine_transform(mask, zx=zx, zy=zy)\n",
        "    return img, mask"
      ],
      "metadata": {
        "id": "HDJDAd1tAMZ7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### random_shear"
      ],
      "metadata": {
        "id": "57kuWC5wAN2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_shear(img, mask, intensity_range=(-0.5, 0.5), u=0.5):\n",
        "    if np.random.random() < u:\n",
        "        sh = np.random.uniform(-intensity_range[0], intensity_range[1])\n",
        "        img = image.apply_affine_transform(img, shear=sh)\n",
        "        mask = image.apply_affine_transform(mask, shear=sh)\n",
        "    return img, mask"
      ],
      "metadata": {
        "id": "Yozuap1RAQ76"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### random_gray"
      ],
      "metadata": {
        "id": "GI9Y9sQDASSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_gray(img, u=0.5):\n",
        "    if np.random.random() < u:\n",
        "        coef = np.array([[[0.114, 0.587, 0.299]]])  # rgb to gray (YCbCr)\n",
        "        gray = np.sum(img * coef, axis=2)\n",
        "        img = np.dstack((gray, gray, gray)) # np.dstack Stack arrays in sequence depth wise\n",
        "    return img"
      ],
      "metadata": {
        "id": "FD_9LblgAU5K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### random_contrast"
      ],
      "metadata": {
        "id": "wXINDlu7AWna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_contrast(img, limit=(-0.3, 0.3), u=0.5):\n",
        "    if np.random.random() < u:\n",
        "        alpha = 1.0 + np.random.uniform(limit[0], limit[1])\n",
        "        coef = np.array([[[0.114, 0.587, 0.299]]])  # rgb to gray (YCbCr)\n",
        "        gray = img * coef\n",
        "        gray = (3.0 * (1.0 - alpha) / gray.size) * np.sum(gray)\n",
        "        img = alpha * img + gray\n",
        "        img = np.clip(img, 0., 1.)\n",
        "    return img"
      ],
      "metadata": {
        "id": "7h_BNd2SAclR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### random_brightness"
      ],
      "metadata": {
        "id": "DKovsJ6AAeAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_brightness(img, limit=(-0.3, 0.3), u=0.5):\n",
        "    if np.random.random() < u:\n",
        "        alpha = 1.0 + np.random.uniform(limit[0], limit[1])\n",
        "        img = alpha * img\n",
        "        img = np.clip(img, 0., 1.)\n",
        "    return img"
      ],
      "metadata": {
        "id": "YzdfuhgwAhFh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### random_saturation"
      ],
      "metadata": {
        "id": "ZI5nyS9cAj65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_saturation(img, limit=(-0.3, 0.3), u=0.5): # randomly changing the intensity of the color\n",
        "    if np.random.random() < u:\n",
        "        alpha = 1.0 + np.random.uniform(limit[0], limit[1])\n",
        "        coef = np.array([[[0.114, 0.587, 0.299]]])\n",
        "        gray = img * coef\n",
        "        gray = np.sum(gray, axis=2, keepdims=True)\n",
        "        img = alpha * img + (1. - alpha) * gray\n",
        "        img = np.clip(img, 0., 1.)\n",
        "    return img"
      ],
      "metadata": {
        "id": "31bQJbZOAmYB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### random_channel_shift"
      ],
      "metadata": {
        "id": "ToXbH4ZOAnxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_channel_shift(x, limit, channel_axis=2):\n",
        "    x = np.rollaxis(x, channel_axis, 0)\n",
        "    min_x, max_x = np.min(x), np.max(x)\n",
        "    channel_images = [np.clip(x_ch + np.random.uniform(-limit, limit), min_x, max_x) for x_ch in x]\n",
        "    x = np.stack(channel_images, axis=0)\n",
        "    x = np.rollaxis(x, 0, channel_axis + 1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "jxoTz5Z7Aq6Z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### random_crop"
      ],
      "metadata": {
        "id": "XetE7YdGAu9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_crop(img, mask, u=0.1):\n",
        "    if np.random.random() < u:\n",
        "        w, h = img.shape[0], img.shape[1]\n",
        "        offsetw = np.random.randint(w//2)\n",
        "        offseth = np.random.randint(w//2)\n",
        "\n",
        "        endw = np.random.randint(w // 2)+w // 2\n",
        "        endh = np.random.randint(w // 2)+w // 2\n",
        "\n",
        "        new_im = img[offsetw:offsetw + endw, offseth:offseth + endh, :]\n",
        "        new_mask = mask[offsetw:offsetw + endw, offseth:offseth + endh, :]\n",
        "\n",
        "        new_im, new_mask = cv2.resize(new_im, interpolation = cv2.INTER_LINEAR, dsize=(w, h)), \\\n",
        "               cv2.resize(new_mask, interpolation=cv2.INTER_LINEAR, dsize=(w, h))\n",
        "\n",
        "        new_mask = new_mask[..., np.newaxis]\n",
        "        return new_im, new_mask\n",
        "    else:\n",
        "        return img, mask"
      ],
      "metadata": {
        "id": "OGDN1zVsAubZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### random_augmentation"
      ],
      "metadata": {
        "id": "wZx58oncA13R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wecTni_O-8-y"
      },
      "outputs": [],
      "source": [
        "# random_brightness, random_contrast, random_saturation, random_rotate\n",
        "# random_shear, random_flip, random_shift, random_zoom\n",
        "def random_augmentation(img, mask):\n",
        "    img = random_brightness(img, limit=(-0.1, 0.1), u=0.05)\n",
        "    img = random_contrast(img, limit=(-0.1, 0.1), u=0.05)\n",
        "    img = random_saturation(img, limit=(-0.1, 0.1), u=0.05)\n",
        "    img, mask = random_rotate(img, mask, rotate_limit=(-10, 10), u=0.05)\n",
        "    img, mask = random_shear(img, mask, intensity_range=(-5, 5), u=0.05)\n",
        "    img, mask = random_flip(img, mask, u=0.5)\n",
        "    img, mask = random_shift(img, mask, w_limit=(-0.1, 0.1), h_limit=(-0.1, 0.1), u=0.05)\n",
        "    img, mask = random_zoom(img, mask, zoom_range=(0.9, 1.1), u=0.05)\n",
        "    return img, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Without Data Augmentation\n",
        "This model is Trained from scratch without any data augmentation. Part of the script is from baseline.py. Architecture is taken from: https://github.com/jocicmarko/ultrasound-nerve-segmentation"
      ],
      "metadata": {
        "id": "e9G-u5g7A4kB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import"
      ],
      "metadata": {
        "id": "2IS9YwdJZG3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse # command-line parsing module in the Python\n",
        "from glob import glob # glob is used to return all file paths that match a specific pattern\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from keras import backend as K\n",
        "from keras import losses\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.layers import Input, MaxPooling2D\n",
        "from keras.layers import concatenate, Conv2D, Conv2DTranspose, Dropout, ReLU\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from numpy import random\n",
        "import tensorflow as tf\n",
        "#from aug_utils import random_augmentation\n",
        "from random import randint"
      ],
      "metadata": {
        "id": "sNBWzMaxBeWK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Global variables"
      ],
      "metadata": {
        "id": "m47afMBEZNFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "input_shape = (64, 64)\n",
        "\n",
        "smooth = 1."
      ],
      "metadata": {
        "id": "eAObhnouEXXJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### custom_activation"
      ],
      "metadata": {
        "id": "SpwNzD39ZS1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_activation(x):\n",
        "    return K.relu(x, alpha=0.0, max_value=1)"
      ],
      "metadata": {
        "id": "pJ0-9b9UBoda"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### focal_loss"
      ],
      "metadata": {
        "id": "a2r959PmZWdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def focal_loss(gamma=2., alpha=.25):\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
        "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
        "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
        "    return focal_loss_fixed"
      ],
      "metadata": {
        "id": "_MC8jVL_BrOC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_unet"
      ],
      "metadata": {
        "id": "BpPq6GGLZa4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unet(do=0, activation=ReLU):\n",
        "    inputs = Input((None, None, 3)) # defining keras input layer\n",
        "    conv1 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(inputs))) # padding same means zero padding\n",
        "    conv1 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(conv1)))  # Dropout(0) layer randomly sets input units to 0\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(pool1)))\n",
        "    conv2 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(conv2)))\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(pool2)))\n",
        "    conv3 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(conv3)))\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(pool3)))\n",
        "    conv4 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(conv4)))\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Dropout(do)(activation()(Conv2D(512, (3, 3), padding='same')(pool4)))\n",
        "    conv5 = Dropout(do)(activation()(Conv2D(512, (3, 3), padding='same')(conv5)))\n",
        "\n",
        "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3) \n",
        "    conv6 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(up6)))     # Conv2DTranspose= Transposed convolution layer (sometimes called Deconvolution).\n",
        "    conv6 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(conv6)))   # concatenate= Layer that concatenates a list of inputs\n",
        "                                                                                    # axis=3 means concatenates in 3rd dimension\n",
        "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "    conv7 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(up7)))\n",
        "    conv7 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(conv7)))\n",
        "\n",
        "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
        "    conv8 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(up8)))\n",
        "    conv8 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(conv8)))\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
        "    conv9 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(up9)))\n",
        "    conv9 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(conv9)))\n",
        "\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[conv10])\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=1e-3), loss=losses.binary_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "GPzDJ7v-BwXB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### read_input"
      ],
      "metadata": {
        "id": "XNC7tyXmZeYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_input(path):\n",
        "    x = np.array(Image.open(path))/255.   #binary image conversion\n",
        "    return x"
      ],
      "metadata": {
        "id": "oYLyupE4BzdJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### read_gt"
      ],
      "metadata": {
        "id": "61v84tw1ZhFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_gt(path):\n",
        "    x = np.array(Image.open(path))/255. #binary image conversion\n",
        "    return x[..., np.newaxis] # numpy.newaxis is used to increase the dimension\n",
        "                              # Consecutive : can be replaced with ...\n",
        "                              # here the input dimension is increased "
      ],
      "metadata": {
        "id": "XTdBPeXABz7i"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### random_crop"
      ],
      "metadata": {
        "id": "lILfYjq2ZjSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_crop(img, mask, crop_size=input_shape[0]):\n",
        "    imgheight= img.shape[0]\n",
        "    imgwidth = img.shape[1]\n",
        "    i = randint(0, imgheight-crop_size)\n",
        "    j = randint(0, imgwidth-crop_size)\n",
        "\n",
        "    return img[i:(i+crop_size), j:(j+crop_size), :], mask[i:(i+crop_size), j:(j+crop_size)]"
      ],
      "metadata": {
        "id": "PSVWXm-JB27J"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### gen"
      ],
      "metadata": {
        "id": "ndQmB8SSZmYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read_input, read_gt, random_crop, random_augmentation\n",
        "def gen(data, au=False):\n",
        "    while True:\n",
        "        repeat = 4\n",
        "        index = random.choice(list(range(len(data))), batch_size // repeat)\n",
        "        index = list(map(int, index))\n",
        "        list_images_base = [read_input(data[i][0]) for i in index]\n",
        "        list_gt_base = [read_gt(data[i][1]) for i in index]\n",
        "\n",
        "        list_images = []\n",
        "        list_gt = []\n",
        "\n",
        "        for image, gt in zip(list_images_base, list_gt_base):\n",
        "\n",
        "            for _ in range(repeat):\n",
        "                image_, gt_ = random_crop(image.copy(), gt.copy())\n",
        "                list_images.append(image_)\n",
        "                list_gt.append(gt_)\n",
        "\n",
        "        list_images_aug = []\n",
        "        list_gt_aug = []\n",
        "\n",
        "        for image, gt in zip(list_images, list_gt):\n",
        "            if au:\n",
        "                image, gt = random_augmentation(image, gt)\n",
        "            list_images_aug.append(image)\n",
        "            list_gt_aug.append(gt)\n",
        "\n",
        "        yield np.array(list_images_aug), np.array(list_gt_aug)"
      ],
      "metadata": {
        "id": "77tNWgNDB-Op"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main"
      ],
      "metadata": {
        "id": "-xcXB-oRFL46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  get_unet, \n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"-d\", \"--dropout\", required=False, help=\"dropout\", type=float, default=0.1)\n",
        "    ap.add_argument(\"-a\", \"--activation\", required=False, help=\"activation\", default=\"ReLU\")\n",
        "    ap.add_argument(\"-f\")\n",
        "\n",
        "    args = vars(ap.parse_args())\n",
        "\n",
        "    activation = globals()[args['activation']]\n",
        "\n",
        "    model_name = \"baseline_unet_do_%s_activation_%s_\"%(args['dropout'], args['activation'])\n",
        "\n",
        "    print(\"Model : %s\\n\\n\"%model_name)\n",
        "\n",
        "    train_data = list(zip(sorted(glob('/content/drive/MyDrive/Medical image segmentation/training/images/*.tif')),\n",
        "                          sorted(glob('/content/drive/MyDrive/Medical image segmentation/training/1st_manual/*.gif'))))\n",
        "\n",
        "    # calling get_unet\n",
        "    model = get_unet(do=args['dropout'], activation=activation)\n",
        "\n",
        "    file_path = model_name + \"weights.best.hdf5\"\n",
        "    try:\n",
        "        model.load_weights(file_path, by_name=True)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    history = model.fit_generator(gen(train_data, au=True), epochs=10, verbose=2,\n",
        "                         steps_per_epoch= 10*len(train_data)//batch_size,\n",
        "                                  use_multiprocessing=True, workers=16)\n",
        "\n",
        "    #model.save_weights(file_path)"
      ],
      "metadata": {
        "id": "oCYwmAwqA9vh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce874d0-6c35-4aef-c66b-a8200e932356"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : baseline_unet_do_0.1_activation_ReLU_\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 - 15s - loss: 0.6008 - accuracy: 0.7717 - 15s/epoch - 1s/step\n",
            "Epoch 2/10\n",
            "12/12 - 2s - loss: 0.4522 - accuracy: 0.8548 - 2s/epoch - 146ms/step\n",
            "Epoch 3/10\n",
            "12/12 - 6s - loss: 0.3326 - accuracy: 0.8933 - 6s/epoch - 498ms/step\n",
            "Epoch 4/10\n",
            "12/12 - 2s - loss: 0.3366 - accuracy: 0.8768 - 2s/epoch - 150ms/step\n",
            "Epoch 5/10\n",
            "12/12 - 7s - loss: 0.3060 - accuracy: 0.8966 - 7s/epoch - 618ms/step\n",
            "Epoch 6/10\n",
            "12/12 - 7s - loss: 0.3213 - accuracy: 0.8889 - 7s/epoch - 554ms/step\n",
            "Epoch 7/10\n",
            "12/12 - 4s - loss: 0.3150 - accuracy: 0.8903 - 4s/epoch - 309ms/step\n",
            "Epoch 8/10\n",
            "12/12 - 1s - loss: 0.3480 - accuracy: 0.8742 - 802ms/epoch - 67ms/step\n",
            "Epoch 9/10\n",
            "12/12 - 3s - loss: 0.2950 - accuracy: 0.9056 - 3s/epoch - 264ms/step\n",
            "Epoch 10/10\n",
            "12/12 - 3s - loss: 0.2901 - accuracy: 0.8978 - 3s/epoch - 229ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(file_path)"
      ],
      "metadata": {
        "id": "p7NZ4966bWzL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Model Without Data Augmentation\n",
        "\n",
        "In this part model without data augmentation is being evaluted. Part of the script is from baseline_predict.py"
      ],
      "metadata": {
        "id": "2zlgEhQMaLKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import"
      ],
      "metadata": {
        "id": "O-ZKZn5Pi2o7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from baseline import get_unet\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.morphology import label\n",
        "from pycocotools import mask as maskUtils\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import cv2\n",
        "from keras.layers import ReLU\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "YRLaiSrwaR-T"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### global variable"
      ],
      "metadata": {
        "id": "xKgm858Oi5jb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batchsize = 4\n",
        "input_shape = (576, 576)"
      ],
      "metadata": {
        "id": "pRZmWR4BaVzr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### batch"
      ],
      "metadata": {
        "id": "vhuI8rZPi-Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch(iterable, n=batchsize):\n",
        "    l = len(iterable)\n",
        "    for ndx in range(0, l, n):\n",
        "        yield iterable[ndx:min(ndx + n, l)]"
      ],
      "metadata": {
        "id": "iw7x6iToab7j"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### read_input"
      ],
      "metadata": {
        "id": "ptCKg3VKjD6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def read_input(path):\n",
        "    #x = np.array(Image.open(path))/255.\n",
        "    #return x"
      ],
      "metadata": {
        "id": "XOLuL9YcadYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### read_gt"
      ],
      "metadata": {
        "id": "Ms2PQt54jBWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_gt(path):\n",
        "    x = np.array(Image.open(path))\n",
        "    return x[..., np.newaxis]/np.max(x)"
      ],
      "metadata": {
        "id": "YTTJQVwsatcb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main"
      ],
      "metadata": {
        "id": "23asglcNjLDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    model_name = \"baseline_unet_do_0.1_activation_ReLU_\"\n",
        "\n",
        "\n",
        "    '''val_data = list(zip(sorted(glob('/content/drive/MyDrive/Medical image segmentation/test/images/*.tif')),\n",
        "                          #sorted(glob('../input/DRIVE/test/2nd_manual/*.gif')),\n",
        "                        sorted(glob('/content/drive/MyDrive/Medical image segmentation/test/mask/*.gif'))))'''\n",
        "\n",
        "    val_data = list(zip(sorted(glob('/content/drive/MyDrive/Medical image segmentation/training/images/*.tif')),\n",
        "                          sorted(glob('/content/drive/MyDrive/Medical image segmentation/training/1st_manual/*.gif')),\n",
        "                        sorted(glob('/content/drive/MyDrive/Medical image segmentation/training/mask/*.gif'))))\n",
        "\n",
        "    try:\n",
        "        os.makedirs(\"/content/\"+model_name+\"test/\", exist_ok=True)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    model = get_unet(do=0.1, activation=ReLU)\n",
        "\n",
        "    file_path = \"/content/baseline_unet_do_0.1_activation_ReLU_weights.best.hdf5\" #file_path = model_name + \"weights.best.hdf5\"\n",
        "\n",
        "    model.load_weights(file_path, by_name=True)\n",
        "\n",
        "    gt_list = []\n",
        "    pred_list = []\n",
        "\n",
        "    for batch_files in tqdm(batch(val_data), total=len(val_data)//batchsize):\n",
        "\n",
        "        imgs = [resize(read_input(image_path[0]), input_shape) for image_path in batch_files]\n",
        "        seg = [read_gt(image_path[1]) for image_path in batch_files]\n",
        "        mask = [read_gt(image_path[2]) for image_path in batch_files]\n",
        "\n",
        "        imgs = np.array(imgs)\n",
        "\n",
        "        pred = model.predict(imgs)\n",
        "\n",
        "        pred_all = (pred)\n",
        "\n",
        "        pred = np.clip(pred, 0, 1)\n",
        "\n",
        "        for i, image_path in enumerate(batch_files):\n",
        "\n",
        "            pred_ = pred[i, :, :, 0]\n",
        "\n",
        "            pred_ = resize(pred_, (584, 565))\n",
        "\n",
        "            mask_ = mask[i]\n",
        "\n",
        "            gt_ = (seg[i]>0.5).astype(int)\n",
        "\n",
        "            gt_flat = []\n",
        "            pred_flat = []\n",
        "\n",
        "            for p in range(pred_.shape[0]):\n",
        "                for q in range(pred_.shape[1]):\n",
        "                    if mask_[p,q]>0.5: # Inside the mask pixels only\n",
        "                        gt_flat.append(gt_[p,q])\n",
        "                        pred_flat.append(pred_[p,q])\n",
        "\n",
        "            print(pred_.size, len(gt_list))\n",
        "\n",
        "            gt_list += gt_flat\n",
        "            pred_list += pred_flat\n",
        "\n",
        "            pred_ = 255.*(pred_ - np.min(pred_))/(np.max(pred_)-np.min(pred_))\n",
        "\n",
        "            image_base = image_path[0].split(\"/\")[-1]\n",
        "\n",
        "            cv2.imwrite(\"/content/\"+model_name+\"test/\"+image_base, pred_)\n",
        "\n",
        "    print(len(gt_list), len(pred_list))\n",
        "    print(\"AUC ROC : \", roc_auc_score(gt_list, pred_list))"
      ],
      "metadata": {
        "id": "hJyBUwQIaJXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f360aff-1222-419e-eb2e-649a34201120"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329960 0\n",
            "329960 225600\n",
            "329960 453286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:09<00:36,  9.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329960 681473\n",
            "329960 909199\n",
            "329960 1136561\n",
            "329960 1361653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:15<00:22,  7.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329960 1589479\n",
            "329960 1816806\n",
            "329960 2044115\n",
            "329960 2271374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:23<00:15,  7.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329960 2499075\n",
            "329960 2724019\n",
            "329960 2951757\n",
            "329960 3178299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:29<00:07,  7.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329960 3405945\n",
            "329960 3633162\n",
            "329960 3860348\n",
            "329960 4086572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:36<00:00,  7.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329960 4314032\n",
            "4541006 4541006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC ROC :  0.4351053011069306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model With Pre-trained on ImageNet VGG Encoder + Data Augmentation\n",
        "This model is Trained on pre-trained on ImageNet VGG encoder and data augmentation. Part of the script is from baseline_aug_vgg.py\n",
        "\n",
        "Architecture is taken from: https://github.com/jocicmarko/ultrasound-nerve-segmentation\n"
      ],
      "metadata": {
        "id": "c1NUQunZLZD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "from glob import glob\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from keras import backend as K\n",
        "from keras import losses\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.layers import Input, MaxPooling2D\n",
        "from keras.layers import concatenate, Conv2D, Conv2DTranspose, Dropout, ReLU\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from numpy import random\n",
        "import tensorflow as tf\n",
        "#from aug_utils import random_augmentation\n",
        "from random import randint"
      ],
      "metadata": {
        "id": "7Mnd4MoRMg7f"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "input_shape = (64, 64)\n",
        "smooth = 1.\n",
        "VGG_PATH = \"/content/drive/MyDrive/Medical image segmentation/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\""
      ],
      "metadata": {
        "id": "fCI0lp1pMkPG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def custom_activation(x):\n",
        "    #return K.relu(x, alpha=0.0, max_value=1)"
      ],
      "metadata": {
        "id": "XFHD23X0MnQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''def focal_loss(gamma=2., alpha=.25):\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
        "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
        "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
        "    return focal_loss_fixed'''"
      ],
      "metadata": {
        "id": "y49RD90XMqmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unet(do=0, activation=ReLU):\n",
        "    inputs = Input((None, None, 3))\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    conv1 = x\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "    x = Dropout(do)(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    conv2 = x\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "    x = Dropout(do)(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "    conv3 = x\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "    x = Dropout(do)(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "    conv4 = x\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "    x = Dropout(do)(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "    conv5 = x\n",
        "    x = Dropout(do)(x)\n",
        "\n",
        "    vgg = Model(inputs, x)\n",
        "    vgg.load_weights(VGG_PATH, by_name=True)\n",
        "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
        "    conv6 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(up6)))\n",
        "    conv6 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(conv6)))\n",
        "\n",
        "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "    conv7 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(up7)))\n",
        "    conv7 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(conv7)))\n",
        "\n",
        "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
        "    conv8 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(up8)))\n",
        "    conv8 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(conv8)))\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
        "    conv9 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(up9)))\n",
        "    conv9 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(conv9)))\n",
        "\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[conv10])\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=1e-3), loss=losses.binary_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "R7Mnn7QdLoY-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def read_input(path):\n",
        "    #x = np.array(Image.open(path))/255.\n",
        "    #return x"
      ],
      "metadata": {
        "id": "4PJNYBOjPden"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#same as basline.py\n",
        "def read_gt(path):\n",
        "    x = np.array(Image.open(path))/255.\n",
        "    return x[..., np.newaxis]"
      ],
      "metadata": {
        "id": "kjfOv_PFPeu2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_crop(img, mask, crop_size=input_shape[0]):\n",
        "    imgheight= img.shape[0]\n",
        "    imgwidth = img.shape[1]\n",
        "    i = randint(0, imgheight-crop_size)\n",
        "    j = randint(0, imgwidth-crop_size)\n",
        "\n",
        "    return img[i:(i+crop_size), j:(j+crop_size), :], mask[i:(i+crop_size), j:(j+crop_size)]"
      ],
      "metadata": {
        "id": "J63QOflaPinu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen(data, au=False):\n",
        "    while True:\n",
        "        repeat = 4\n",
        "        index = random.choice(list(range(len(data))), batch_size // repeat)\n",
        "        index = list(map(int, index))\n",
        "        list_images_base = [read_input(data[i][0]) for i in index]\n",
        "        list_gt_base = [read_gt(data[i][1]) for i in index]\n",
        "\n",
        "        list_images_aug = []\n",
        "        list_gt_aug = []\n",
        "\n",
        "        for image, gt in zip(list_images_base, list_gt_base):\n",
        "            if au:\n",
        "                image, gt = random_augmentation(image, gt)\n",
        "            list_images_aug.append(image)\n",
        "            list_gt_aug.append(gt)\n",
        "\n",
        "        list_images = []\n",
        "        list_gt = []\n",
        "\n",
        "        for image, gt in zip(list_images_aug, list_gt_aug):\n",
        "\n",
        "            for _ in range(repeat):\n",
        "                image_, gt_ = random_crop(image, gt)\n",
        "                list_images.append(image_)\n",
        "                list_gt.append(gt_)\n",
        "\n",
        "        yield np.array(list_images), np.array(list_gt)"
      ],
      "metadata": {
        "id": "_hg0WJpbPcKG"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main"
      ],
      "metadata": {
        "id": "XIRVHTCpX6RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"-d\", \"--dropout\", required=False, help=\"dropout\", type=float, default=0.1)\n",
        "    ap.add_argument(\"-a\", \"--activation\", required=False, help=\"activation\", default=\"ReLU\")\n",
        "    ap.add_argument(\"-f\")\n",
        "\n",
        "    args = vars(ap.parse_args())\n",
        "\n",
        "    activation = globals()[args['activation']]\n",
        "\n",
        "    model_name = \"baseline_unet_aug_vgg_do_%s_activation_%s_\"%(args['dropout'], args['activation'])\n",
        "\n",
        "    print(\"Model : %s\"%model_name)\n",
        "\n",
        "    train_data = list(zip(sorted(glob('/content/drive/MyDrive/Medical image segmentation/training/images/*.tif')),\n",
        "                          sorted(glob('/content/drive/MyDrive/Medical image segmentation/training/1st_manual/*.gif'))))\n",
        "\n",
        "\n",
        "    model = get_unet(do=args['dropout'], activation=activation)\n",
        "\n",
        "    file_path = model_name + \"weights.best.hdf5\"\n",
        "    try:\n",
        "        model.load_weights(file_path, by_name=True)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    history = model.fit_generator(gen(train_data, au=True), epochs=10, verbose=2,\n",
        "                         steps_per_epoch= 10*len(train_data)//batch_size,\n",
        "                                  use_multiprocessing=True, workers=16)\n",
        "\n",
        "    #model.save_weights(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SLuz9_kPmj2",
        "outputId": "3baaa03d-f9ad-4ac7-858e-b7065b94258e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : baseline_unet_aug_vgg_do_0.1_activation_ReLU_\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 - 5s - loss: 0.4316 - accuracy: 0.8487 - 5s/epoch - 395ms/step\n",
            "Epoch 2/10\n",
            "12/12 - 3s - loss: 0.3045 - accuracy: 0.8944 - 3s/epoch - 249ms/step\n",
            "Epoch 3/10\n",
            "12/12 - 3s - loss: 0.2917 - accuracy: 0.8894 - 3s/epoch - 226ms/step\n",
            "Epoch 4/10\n",
            "12/12 - 2s - loss: 0.2490 - accuracy: 0.9047 - 2s/epoch - 173ms/step\n",
            "Epoch 5/10\n",
            "12/12 - 2s - loss: 0.2557 - accuracy: 0.9050 - 2s/epoch - 176ms/step\n",
            "Epoch 6/10\n",
            "12/12 - 3s - loss: 0.2540 - accuracy: 0.8986 - 3s/epoch - 235ms/step\n",
            "Epoch 7/10\n",
            "12/12 - 3s - loss: 0.1967 - accuracy: 0.9059 - 3s/epoch - 249ms/step\n",
            "Epoch 8/10\n",
            "12/12 - 1s - loss: 0.1840 - accuracy: 0.9169 - 1s/epoch - 119ms/step\n",
            "Epoch 9/10\n",
            "12/12 - 1s - loss: 0.1707 - accuracy: 0.9356 - 826ms/epoch - 69ms/step\n",
            "Epoch 10/10\n",
            "12/12 - 2s - loss: 0.1586 - accuracy: 0.9398 - 2s/epoch - 180ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(file_path)"
      ],
      "metadata": {
        "id": "xNpb0uHpSayY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Model With Pre-trained on ImageNet VGG Encoder + Data Augmentation.\n",
        "\n",
        "In this part model with pre-trained on imageNet VGG encoder and data augmetation is being evaluted. Part of the script is from baseline_aug_vgg_predict.py."
      ],
      "metadata": {
        "id": "nZYJn-b4Xiw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from baseline_aug_vgg import get_unet\n",
        "from glob import glob\n",
        "from cv2 import imread\n",
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.morphology import label\n",
        "from pycocotools import mask as maskUtils\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import cv2\n",
        "from keras.layers import ReLU\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "wi3c8puVX_kG"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batchsize = 4\n",
        "input_shape = (576, 576)"
      ],
      "metadata": {
        "id": "ucBHgqIMYCCf"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch(iterable, n=batchsize):\n",
        "    l = len(iterable)\n",
        "    for ndx in range(0, l, n):\n",
        "        yield iterable[ndx:min(ndx + n, l)]"
      ],
      "metadata": {
        "id": "ECfy5fbOYEof"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_input(path):\n",
        "    x = np.array(Image.open(path))/255.\n",
        "    return x"
      ],
      "metadata": {
        "id": "9egE55AVYGNH"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_gt(path):\n",
        "    x = np.array(Image.open(path))\n",
        "    return x[..., np.newaxis]/np.max(x)"
      ],
      "metadata": {
        "id": "UpKkxb-yYJUn"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main"
      ],
      "metadata": {
        "id": "sPuZkLJneFo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    model_name = \"baseline_unet_aug_vgg_do_0.1_activation_ReLU_\"\n",
        "\n",
        "\n",
        "    '''val_data = list(zip(sorted(glob('../input/DRIVE/test/images/*.tif')),\n",
        "                          sorted(glob('../input/DRIVE/test/2nd_manual/*.gif')),\n",
        "                        sorted(glob('../input/DRIVE/test/mask/*.gif'))))'''\n",
        "\n",
        "    val_data = list(zip(sorted(glob('/content/drive/MyDrive/Medical image segmentation/training/images/*.tif')),\n",
        "                          sorted(glob('/content/drive/MyDrive/Medical image segmentation/training/1st_manual/*.gif')),\n",
        "                        sorted(glob('/content/drive/MyDrive/Medical image segmentation/training/mask/*.gif'))))\n",
        "\n",
        "    try:\n",
        "        os.makedirs(\"/content/\"+model_name+\"test/\", exist_ok=True)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    model = get_unet(do=0.1, activation=ReLU)\n",
        "\n",
        "    file_path = \"/content/baseline_unet_aug_vgg_do_0.1_activation_ReLU_weights.best.hdf5\" #model_name + \"weights.best.hdf5\"\n",
        "\n",
        "    model.load_weights(file_path, by_name=True)\n",
        "\n",
        "    gt_list = []\n",
        "    pred_list = []\n",
        "\n",
        "    for batch_files in tqdm(batch(val_data), total=len(val_data)//batchsize):\n",
        "\n",
        "        imgs = [resize(read_input(image_path[0]), input_shape) for image_path in batch_files]\n",
        "        seg = [read_gt(image_path[1]) for image_path in batch_files]\n",
        "        mask = [read_gt(image_path[2]) for image_path in batch_files]\n",
        "\n",
        "        imgs = np.array(imgs)\n",
        "\n",
        "        pred = model.predict(imgs)\n",
        "\n",
        "        pred_all = (pred)\n",
        "\n",
        "        pred = np.clip(pred, 0, 1)\n",
        "\n",
        "        for i, image_path in enumerate(batch_files):\n",
        "\n",
        "            pred_ = pred[i, :, :, 0]\n",
        "\n",
        "            pred_ = resize(pred_, (584, 565))\n",
        "\n",
        "            mask_ = mask[i]\n",
        "\n",
        "            gt_ = (seg[i]>0.5).astype(int)\n",
        "\n",
        "            gt_flat = []\n",
        "            pred_flat = []\n",
        "\n",
        "            for p in range(pred_.shape[0]):\n",
        "                for q in range(pred_.shape[1]):\n",
        "                    if mask_[p,q]>0.5: # Inside the mask pixels only\n",
        "                        gt_flat.append(gt_[p,q])\n",
        "                        pred_flat.append(pred_[p,q])\n",
        "\n",
        "            print(pred_.size, len(gt_list))\n",
        "\n",
        "            gt_list += gt_flat\n",
        "            pred_list += pred_flat\n",
        "\n",
        "            pred_ = 255.*(pred_ - np.min(pred_))/(np.max(pred_)-np.min(pred_))\n",
        "\n",
        "            image_base = image_path[0].split(\"/\")[-1]\n",
        "\n",
        "            cv2.imwrite(\"/content/\"+model_name+\"test/\"+image_base, pred_)\n",
        "\n",
        "    print(len(gt_list), len(pred_list))\n",
        "    print(\"AUC ROC : \", roc_auc_score(gt_list, pred_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUFj-WKUXvX3",
        "outputId": "0e1ee0f7-2579-4f64-c695-22786b626760"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329960 0\n",
            "329960 225600\n",
            "329960 453286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:08<00:33,  8.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329960 681473\n",
            "329960 909199\n",
            "329960 1136561\n",
            "329960 1361653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:11<00:16,  5.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329960 1589479\n",
            "329960 1816806\n",
            "329960 2044115\n",
            "329960 2271374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:15<00:09,  4.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329960 2499075\n",
            "329960 2724019\n",
            "329960 2951757\n",
            "329960 3178299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:18<00:04,  4.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329960 3405945\n",
            "329960 3633162\n",
            "329960 3860348\n",
            "329960 4086572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:21<00:00,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329960 4314032\n",
            "4541006 4541006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC ROC :  0.5150285290619331\n"
          ]
        }
      ]
    }
  ]
}